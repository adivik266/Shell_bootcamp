{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222c9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e04eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b8cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abe982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/21 08:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0043fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cba4cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 23, 4, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd=sc.parallelize([1,23,4,5])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a09c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 46, 8, 10]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultrdd=rdd.map(lambda x:x*2)\n",
    "resultrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d0aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28193d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 4, 3, 6, 4, 8, 5, 10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultrdd1=rdd1.flatMap(lambda x:(x,x*2))\n",
    "resultrdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e9c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3=sc.parallelize([1,2,3,4,5,6,7])\n",
    "resultrdd3=rdd3.filter(lambda x:x%2==0)\n",
    "resultrdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc76351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 3), (1, 8), (3, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4=sc.parallelize([(1,2),(3,4),(1,6),(2,3)])\n",
    "res4=rdd4.reduceByKey(lambda x,y:x+y)\n",
    "res4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545718ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, <pyspark.resultiterable.ResultIterable at 0x7f69ec74e5d0>),\n",
       " (1, <pyspark.resultiterable.ResultIterable at 0x7f69f9fee650>),\n",
       " (3, <pyspark.resultiterable.ResultIterable at 0x7f69f9fee6d0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5=sc.parallelize([(1,2),(3,4),(1,6),(2,3)])\n",
    "res5=rdd5.groupByKey()\n",
    "res5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200dc5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 2, Values: [3]\n",
      "Key: 1, Values: [2, 6]\n",
      "Key: 3, Values: [4]\n"
     ]
    }
   ],
   "source": [
    "for key, values in res5.collect():\n",
    "    print(f'Key: {key}, Values: {list(values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100a5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list=['this','is','a','sample','text','document','for','word','count','example']\n",
    "rdd=sc.parallelize(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7725459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('this', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('sample', 1),\n",
       " ('text', 1),\n",
       " ('document', 1),\n",
       " ('for', 1),\n",
       " ('word', 1),\n",
       " ('count', 1),\n",
       " ('example', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count=rdd.map(lambda x: (x,1))\n",
    "word_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "940174c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this: 1\n",
      "sample: 1\n",
      "text: 1\n",
      "for: 1\n",
      "word: 1\n",
      "is: 1\n",
      "a: 1\n",
      "document: 1\n",
      "count: 1\n",
      "example: 1\n"
     ]
    }
   ],
   "source": [
    "word_counts=rdd.map(lambda x: (x,1)).reduceByKey(lambda a,b:a+b)\n",
    "results=word_counts.collect()\n",
    "for word,count in results:\n",
    "    print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a083a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaserdd=sc.textFile(\"/home/labuser/Downloads/purchases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d171fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',apples,oranges', 'June,3,0', 'Robert,2,3', 'Lily,0,7', 'David,1,2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchaserdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d050b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+\n",
      "|   _c0|   _c1|    _c2|\n",
      "+------+------+-------+\n",
      "|  null|apples|oranges|\n",
      "|  June|     3|      0|\n",
      "|Robert|     2|      3|\n",
      "|  Lily|     0|      7|\n",
      "| David|     1|      2|\n",
      "+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchasedf=spark.read.csv(\"/home/labuser/Downloads/purchases.csv\")\n",
    "purchasedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6a52a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+\n",
      "|   _c0|apples|oranges|\n",
      "+------+------+-------+\n",
      "|  June|     3|      0|\n",
      "|Robert|     2|      3|\n",
      "|  Lily|     0|      7|\n",
      "| David|     1|      2|\n",
      "+------+------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 09:02:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , apples, oranges\n",
      " Schema: _c0, apples, oranges\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/labuser/Downloads/purchases.csv\n"
     ]
    }
   ],
   "source": [
    "purchasedf_1=spark.read.option('inferSchema',True).option('header',True).csv(\"/home/labuser/Downloads/purchases.csv\")\n",
    "purchasedf_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3185bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- apples: integer (nullable = true)\n",
      " |-- oranges: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchasedf_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b672d05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 09:40:34 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 3\n",
      "CSV file: file:///home/labuser/Downloads/IMDB-Movie-Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+\n",
      "|Rank|               Title|               Genre|\n",
      "+----+--------------------+--------------------+\n",
      "|   1|Guardians of the ...|Action,Adventure,...|\n",
      "|   2|          Prometheus|Adventure,Mystery...|\n",
      "|   3|               Split|     Horror,Thriller|\n",
      "|   4|                Sing|Animation,Comedy,...|\n",
      "|   5|       Suicide Squad|Action,Adventure,...|\n",
      "|   6|      The Great Wall|Action,Adventure,...|\n",
      "|   7|          La La Land|  Comedy,Drama,Music|\n",
      "|   8|            Mindhorn|              Comedy|\n",
      "|   9|  The Lost City of Z|Action,Adventure,...|\n",
      "|  10|          Passengers|Adventure,Drama,R...|\n",
      "|  11|Fantastic Beasts ...|Adventure,Family,...|\n",
      "|  12|      Hidden Figures|Biography,Drama,H...|\n",
      "|  13|           Rogue One|Action,Adventure,...|\n",
      "|  14|               Moana|Animation,Adventu...|\n",
      "|  15|            Colossal| Action,Comedy,Drama|\n",
      "|  16|The Secret Life o...|Animation,Adventu...|\n",
      "|  17|       Hacksaw Ridge|Biography,Drama,H...|\n",
      "|  18|        Jason Bourne|     Action,Thriller|\n",
      "|  19|                Lion|     Biography,Drama|\n",
      "|  20|             Arrival|Drama,Mystery,Sci-Fi|\n",
      "+----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 24:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "udfschema=StructType([StructField('Rank', IntegerType(),False),\n",
    "                    StructField('Title', StringType(), False),\n",
    "                    StructField('Genre', StringType(), True)])\n",
    "purchasesF_2=spark.read.schema(udfschema).option('header',True).csv(\"/home/labuser/Downloads/IMDB-Movie-Data.csv\")\n",
    "purchasesF_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbf510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
